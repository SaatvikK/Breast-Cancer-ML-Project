{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03/02/2025\n",
    "# CONTROLLER\n",
    "###################\n",
    "\n",
    "from ipynb.fs.full.MLmodels import runModels\n",
    "from ipynb.fs.full.preprocessing import dataPreProcessing\n",
    "\n",
    "\n",
    "def controller(\n",
    "    inFile = \"../data/data2.csv\", setNum = 1, inputDF = None, procs = [\"clean\", \"predMap\", \"debiasing\", \"CFS\", \"splitSet\"], \n",
    "    k = 10, tauRed = 0.8, inTestSize = 0.2, debiasingMode = \"smote\", run = True\n",
    "):\n",
    "  returnData = {}\n",
    "  vars = dataPreProcessing(\n",
    "      dsFile = inFile, set = setNum, df = inputDF, processes = procs, kFeatures = k, tauRedundancy = tauRed, testSize = inTestSize, debiasTechnique  = debiasingMode\n",
    "  );\n",
    "  df = vars[\"df\"]\n",
    "\n",
    "  if run and \"splitSet\" in procs:\n",
    "    [Ypreds, models] = runModels(vars[\"Xtrain\"], vars[\"Ytrain\"], vars[\"Xtest\"], modes = [\"train\", \"test\"])\n",
    "    vars[\"Ypreds\"] = Ypreds\n",
    "    vars[\"models\"] = models\n",
    "  return vars\n",
    "\n",
    "#vars = controller(\"../data/data2.csv\", setNum = 2, inputDF = None, procs = [\"clean\", \"predMap\", \"debiasing\", \"CFS\", \"splitSet\"], k = 6, tauRed = 0.8, inTestSize = 0.2, debiasingMode = \"over\", run = True);\n",
    "#Xtrain = vars[\"Xtrain\"]\n",
    "#Ytrain = vars[\"Ytrain\"]\n",
    "#Xtest = vars[\"Xtest\"]\n",
    "#Ytest = vars[\"Ytest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03/02/2025\n",
    "# CONTROLLER\n",
    "###################\n",
    "\n",
    "from ipynb.fs.full.MLmodels import runModels\n",
    "from ipynb.fs.full.preprocessing import dataPreProcessing\n",
    "\n",
    "\n",
    "def controller(\n",
    "    inFile = \"../data/data2.csv\", setNum = 1, inputDF = None, procs = [\"clean\", \"predMap\", \"debiasing\", \"CFS\", \"splitSet\"], \n",
    "    k = 10, tauRed = 0.8, inTestSize = 0.2, debiasingMode = \"smote\", run = True\n",
    "):\n",
    "  returnData = {}\n",
    "  vars = dataPreProcessing(\n",
    "      dsFile = inFile, set = setNum, df = inputDF, processes = procs, kFeatures = k, tauRedundancy = tauRed, testSize = inTestSize, debiasTechnique  = debiasingMode\n",
    "  );\n",
    "  df = vars[\"df\"]\n",
    "\n",
    "  if run and \"splitSet\" in procs:\n",
    "    [Ypreds, models] = runModels(vars[\"Xtrain\"], vars[\"Ytrain\"], vars[\"Xtest\"], modes = [\"train\", \"test\"])\n",
    "    vars[\"Ypreds\"] = Ypreds\n",
    "    vars[\"models\"] = models\n",
    "  return vars\n",
    "\n",
    "vars = controller(\"../data/data2.csv\", setNum = 2, inputDF = None, procs = [\"clean\", \"predMap\", \"debiasing\", \"CFS\", \"splitSet\"], k = 6, tauRed = 0.8, inTestSize = 0.2, debiasingMode = \"over\", run = True);\n",
    "Xtrain = vars[\"Xtrain\"]\n",
    "Ytrain = vars[\"Ytrain\"]\n",
    "Xtest = vars[\"Xtest\"]\n",
    "Ytest = vars[\"Ytest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "\n",
    "# EVALUATE MODELS\n",
    "\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12/2024\n",
    "# NORMAL PERFORMANCE METRICS\n",
    "from ipynb.fs.full.performance import performanceEval\n",
    "\n",
    "# logistic reg\n",
    "print(\"============= LOGISTIC REGRESSION MODEL PERFORMANCE =============\")\n",
    "regMetrics = performanceEval(Ytest, vars[\"Ypreds\"][\"Ypred_regModel\"], \"Logistic Regression model\")\n",
    "print(regMetrics)\n",
    "print(\"=================================================================\")\n",
    "\n",
    "# svm (linear kernel)\n",
    "print(\"============= SVM (LINEAR KERNEL) MODEL PERFORMANCE =============\")\n",
    "svmLinMetrics = performanceEval(Ytest, vars[\"Ypreds\"][\"Ypred_svmModel\"], \"SVM (Linear Kernel) model\")\n",
    "print(svmLinMetrics)\n",
    "print(\"=================================================================\")\n",
    "\n",
    "# NBC\n",
    "print(\"============= NAIVE BAYES CLASSIFIER MODEL PERFORMANCE =============\")\n",
    "nbcMetrics = performanceEval(Ytest, vars[\"Ypreds\"][\"Ypred_nbcModel\"], \"NBC model\")\n",
    "print(nbcMetrics)\n",
    "print(\"=================================================================\")\n",
    "\n",
    "# K-NN\n",
    "print(\"============= K-NN MODEL MODEL PERFORMANCE =============\")\n",
    "knnMetrics = performanceEval(Ytest, vars[\"Ypreds\"][\"Ypred_knnModel\"], \"K-NN model\")\n",
    "print(knnMetrics)\n",
    "print(\"=================================================================\")\n",
    "\n",
    "# Decision Tree\n",
    "print(\"============= DECISION TREE MODEL PERFORMANCE =============\")\n",
    "decTreeMetrics = performanceEval(Ytest, vars[\"Ypreds\"][\"Ypred_dtModel\"], \"K-NN model\")\n",
    "print(decTreeMetrics)\n",
    "print(\"=================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03/02/2025\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar Chart of Perf Metrics\n",
    "modelNames = [\"Log Reg\", \"SVM Linear\", \"NB Classifier\", \"K-NN Model\", \"Decision Tree\"]\n",
    "modelMetrics = [regMetrics, svmLinMetrics, nbcMetrics, knnMetrics, decTreeMetrics]\n",
    "acc, spec, sen, rec, prec = [], [], [], [], []\n",
    "\n",
    "# Extract metrics for each model\n",
    "for metrics in modelMetrics:\n",
    "    acc.append(metrics[\"accuracy\"])\n",
    "    spec.append(metrics[\"specificity\"])\n",
    "    sen.append(metrics[\"sensitivity\"])\n",
    "    rec.append(metrics[\"recall\"])\n",
    "    prec.append(metrics[\"precision\"])\n",
    "\n",
    "# Set up positions for grouped bars\n",
    "x = np.arange(len(modelNames))  # Label locations for each model\n",
    "width = 0.15                    # Width of each bar\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create bars for each metric\n",
    "rects1 = ax.bar(x - 2 * width, acc, width, label=\"Accuracy\")\n",
    "rects2 = ax.bar(x - width, spec, width, label=\"Specificity\")\n",
    "rects3 = ax.bar(x, sen, width, label=\"Sensitivity\")\n",
    "rects4 = ax.bar(x + width, rec, width, label=\"Recall\")\n",
    "rects5 = ax.bar(x + 2 * width, prec, width, label=\"Precision\")\n",
    "\n",
    "# Find the maximum metric value to set the top margin\n",
    "y_max = max(acc + spec + sen + rec + prec)\n",
    "ax.set_ylim(0, y_max + 8)  # Increase the limit more so the labels don't hit the title\n",
    "\n",
    "# Add labels, title, and custom x-axis tick labels, etc.\n",
    "# The \"pad\" parameter moves the title further above the plot\n",
    "ax.set_title('Performance Metrics by Model', pad=20)\n",
    "ax.set_ylabel('Score (%)')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(modelNames)\n",
    "ax.legend()\n",
    "\n",
    "# Function to add labels above each bar with vertical text\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a vertically rotated text label above each bar, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate(f'{height:.2f}',\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 10),          # Increase offset to 10 points above the bar\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    rotation=90,\n",
    "                    clip_on=False)\n",
    "\n",
    "# Label each set of bars\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "autolabel(rects4)\n",
    "autolabel(rects5)\n",
    "\n",
    "# Make room for the labels by adjusting the layout,\n",
    "# and add a bit more space above if needed:\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "\n",
    "# best k so far = 6 (w tauRed = 0.8) (FOR DATA SET 1)\n",
    "# best k so far = 6 (w tauRed = 0.8) (FOR DATA SET 1)\n",
    "\n",
    "\n",
    "##################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
