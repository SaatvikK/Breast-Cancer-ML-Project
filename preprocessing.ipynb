{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning\n",
    "def dataClean(df):\n",
    "  # there's an extra column at the end of the data set that needs removing.\n",
    "  df = df.drop(columns=[\"Unnamed: 32\"])\n",
    "  # other than this, there is no more data cleaning to do.\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we isolate the classification column of the datasset ('diagnosis').\n",
    "# Because 'diagnosis' uses M & B as labels and CFS uses numbers, we map\n",
    "# M and B to 1 and 0, respectively.\n",
    "def predClassMapping(df):\n",
    "  df['diagnosis'] = pd.Series(df.diagnosis).map({'M':1,'B':0});\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12/24\n",
    "# CORRELATION FEATURE SELECTION\n",
    "\n",
    "# tauRed = 0.8, k = 10\n",
    "def corrFeatureSelection(df, k = 10, tauRedundancy = 0.8):\n",
    "  # 1) Sort features by absolute correlation with the label (descending)\n",
    "  targetCorr = df.corr()['diagnosis'].abs().sort_values(ascending=False)\n",
    "\n",
    "  # 2) Now pick features one by one from the most strongly correlated\n",
    "  #    to the least, but skip any feature that is \"too correlated\"\n",
    "\n",
    "  selectedFeatures = []\n",
    "\n",
    "  for feature in targetCorr.index:\n",
    "      if feature == 'diagnosis':\n",
    "          continue  # Skip the label itself\n",
    "\n",
    "      # Check correlation with already selected features\n",
    "      aboveThreshold = False\n",
    "      for alreadySelected in selectedFeatures:\n",
    "          # If the correlation is above the threshold, skip\n",
    "          if abs(df[feature].corr(df[alreadySelected])) > tauRedundancy:\n",
    "              aboveThreshold = True\n",
    "              break\n",
    "\n",
    "      if not aboveThreshold:\n",
    "          selectedFeatures.append(feature)\n",
    "\n",
    "      # If we already have our 10 features, stop\n",
    "      if len(selectedFeatures) == k:\n",
    "          break\n",
    "\n",
    "  print(\"Selected features:\", selectedFeatures)\n",
    "  print(\"Num features:\", len(selectedFeatures))\n",
    "  # This will give up to 10 features that are:\n",
    "  # - highly correlated with the label (because we started with that sorted list),\n",
    "  # - but have low correlation with each other (due to our threshold check).\n",
    "\n",
    "  selectedDF = df[['diagnosis'] + selectedFeatures]\n",
    "\n",
    "  return { \"sfCorrMatrix\": selectedDF.corr(), \"selectedDF\": selectedDF }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10/24\n",
    "# SPLIT DATA SET\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def splitData(df, testSize = 0.20):\n",
    "  # Split the label column from the features\n",
    "  Y = df.loc[:, 'diagnosis']\n",
    "  X = df.loc[:, df.columns != 'diagnosis']\n",
    "\n",
    "  # Now split the X and Y datasets into train/test (0.8/0.2 split by default)\n",
    "  Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=testSize, random_state=23)\n",
    "  return [Xtrain, Xtest, Ytrain, Ytest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01/02/2025\n",
    "# This is the data preprocessing handler. Can be used to execute any one or multiple forms of data preprocessing (cleaning, mapping, feature selection, data splitting).\n",
    "# NOTE: If data set splitting and CFS are to be done in the same call, the CFS option MUST be first in the `processes` array (so that the dataset is feature selected, and THEN split)\n",
    "def dataPreProcessing(dsFile = \"data\", df = None, processes = [\"clean\", \"predMap\", \"CFS\", \"splitSet\"], kFeatures = 10, tauRedundancy = 0.8, testSize = 0.20):\n",
    "  returnVars = {\"df\": None, \"CFS Corr Matrix\": None, \"Xtrain\": None, \"Xtest\": None, \"Ytrain\": None, \"Ytest\": None}\n",
    "  if df is None:\n",
    "    df = pd.read_csv(dsFile + '.csv')\n",
    "\n",
    "  for process in processes:\n",
    "    match process:\n",
    "      case \"clean\":\n",
    "        df = dataClean(df)\n",
    "      case \"predMap\":\n",
    "        df = predClassMapping(df)\n",
    "      case \"CFS\":\n",
    "        res = corrFeatureSelection(df, kFeatures, tauRedundancy)\n",
    "        returnVars[\"CFS Corr Matrix\"] = res[\"sfCorrMatrix\"]\n",
    "        df = res[\"selectedDF\"]\n",
    "      case \"splitSet\":\n",
    "        Xtrain, Xtest, Ytrain, Ytest = splitData(df, testSize)\n",
    "        returnVars[\"Xtrain\"] = Xtrain\n",
    "        returnVars[\"Xtest\"] = Xtest\n",
    "        returnVars[\"Ytrain\"] = Ytrain\n",
    "        returnVars[\"Ytest\"] = Ytest\n",
    "      case _:\n",
    "        raise Exception(\"Processes param is empty. Options: ['clean', 'predMap', 'CFS', 'splitSet']\")\n",
    "\n",
    "  returnVars[\"df\"] = df\n",
    "  return returnVars"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
